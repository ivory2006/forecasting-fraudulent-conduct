#-multi-algorithm for kaggle,Author:ssb--
from sklearn import metrics, cross_validation
from sklearn import datasets
import numpy as np
from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,classification_report,confusion_matrix
import pandas as pd
import pprint
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split,cross_val_score
df=pd.read_csv('train_sample1.csv')
samples=df.loc[:,['ip','app','device','os','channel','click_time']]
target=df.loc[:,'is_attributed']
cv_folds = cross_validation.StratifiedKFold(target, n_folds=5, shuffle=False, random_state=0)
#I haven't used cross validation,the results is over-fitting
samples_train,samples_test,target_train,target_test = train_test_split(samples,target,test_size=0.2,random_state=0)
RF=RandomForestClassifier(oob_score=True, random_state=0)
RF_train=RF.fit(samples_train,target_train)
target_pred_SL_R=RF_train.predict(samples_test) #testing dataset
accuracy_SL_R=accuracy_score(target_test,target_pred_SL_R) #accuracy rate
randomforest_report=classification_report(target_test,target_pred_SL_R) #report
lines_RF = randomforest_report
print(lines_RF)
print(accuracy_SL_R)
#logistic cross validation,the results is over-fitting
from sklearn.linear_model import LogisticRegression
Logistic_predict = cross_validation.cross_val_predict(LogisticRegression(), samples, target, cv=cv_folds)
Logistic_score =cross_validation.cross_val_score(LogisticRegression(), samples, target, cv=cv_folds)
Logistic_mean=Logistic_score.mean()
Logistic_std=Logistic_score.std()
Logistic_report=classification_report(target,Logistic_predict) #report
print("Logistic accuracy mean is",Logistic_mean)
print("the Logistic standard deviation is",Logistic_std)
print("the Logistic report is",Logistic_report)
#randomforest cross validation
from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier
randomForest_predict = cross_validation.cross_val_predict(RandomForestClassifier(), samples, target, cv=cv_folds)
randomforest_score = cross_validation.cross_val_score(RandomForestClassifier(), samples, target, cv=cv_folds)
randomforest_mean=randomforest_score.mean()
randomforest_std=randomforest_score.std()
randomforest_report=classification_report(target,randomForest_predict) #report
print("randomforest accuracy mean is",randomforest_mean)
print("the randomforest standard deviation is",randomforest_std)
print("the randomforest report is",randomforest_report)
#AdaBoostClassifier
AdaBoost_predict = cross_validation.cross_val_predict(AdaBoostClassifier(), samples, target, cv=cv_folds)
AdaBoost_score = cross_validation.cross_val_score(AdaBoostClassifier(), samples, target, cv=cv_folds)
AdaBoost_mean=AdaBoost_score.mean()
AdaBoost_std=randomforest_score.std()
AdaBoost_report=classification_report(target,AdaBoost_predict) #report
print("AdaBoost accuracy mean is",AdaBoost_mean)
print("the AdaBoost standard deviation is",AdaBoost_std)
print("the AdaBoost report is",AdaBoost_report)
#NaiveBays
from sklearn.naive_bayes import GaussianNB
bayes_predict = cross_validation.cross_val_predict(GaussianNB(), samples, target, cv=cv_folds)
bayes_score = cross_validation.cross_val_score(GaussianNB(), samples, target, cv=cv_folds)
bayes_mean=bayes_score.mean()
bayes_std=bayes_score.std()
bayes_report=classification_report(target,bayes_predict) #report
print("bayes accuracy mean is",bayes_mean)
print("the bayes standard deviation is",bayes_std)
print("the bayes report is",bayes_report)
